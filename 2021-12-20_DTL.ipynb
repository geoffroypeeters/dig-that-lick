{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dig-That-Lick\n",
    "\n",
    "- Author: geoffroy.peeters@telecom-paris.fr\n",
    "- Date: 2021-12-20\n",
    "\n",
    "Set of tools to merge and convert all the files into a single json file\n",
    "\n",
    "![](./IMG_0921.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_verbose = True\n",
    "\n",
    "do_localaudio = False\n",
    "do_pitchcsv = False\n",
    "do_fingerprint = False\n",
    "\n",
    "# --- targetkeyname TKN\n",
    "\n",
    "ROOT = '/Users/peeters/Dropbox/_work/_dtl/DTL1000/'\n",
    "# ---------------------\n",
    "style_FILE = ROOT + 'styles-20210503.csv'\n",
    "style_TKN = 'metadata_#styles_csv'\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "audio_DIR1 = '/Volumes/peeters/_2020-05_dig-that-lick/IUC-audio-files/*.aiff'\n",
    "audio_DIR2 = '/Volumes/peeters/_2020-05_dig-that-lick/JE-audio-files/*.wav'\n",
    "audio_TKN = 'filename_#local'\n",
    "\n",
    "# ---------------------\n",
    "audioduration_FILE = ROOT + '2021-06-29_file_duration.json'\n",
    "\n",
    "# ---------------------\n",
    "# segmentation\n",
    "# ---------------------\n",
    "segment_FILE = ROOT + 'DTL_1000_segmentations-20211213.csv'\n",
    "#segment_TKN = 'segment'\n",
    "segment_segment_TKN = 'segment_#DTL_1000_segmentations_csv'\n",
    "segment_metadata_TKN = 'metadata_#DTL_1000_segmentations_csv'\n",
    "\n",
    "mapfilename_FILE = ROOT + 'DTL_file_map.csv'\n",
    "\n",
    "# ---------------------\n",
    "# solo segment and metadata\n",
    "# ---------------------\n",
    "metadataANDsolo_FILE = ROOT + 'metadata_full_compressed_v12-SD-20211217.csv'\n",
    "metadataANDsolo_solo_TKN = 'solo_#metadata_full_compressed_csv'\n",
    "metadataANDsolo_metadata_TKN = 'metadata_#metadata_full_compressed_csv'\n",
    "\n",
    "# ---------------------\n",
    "# solo transcription\n",
    "# ---------------------\n",
    "pitch_DIR = ROOT + 'with_phrase_info_20210522/'\n",
    "pitch_TKN = 'solo_transcription'\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# simon meta-data\n",
    "# ---------------------\n",
    "csv1960_FILE_l = [ROOT + 'DTL1000-metadata-20211216/1960s.csv_110_musinstr.json',\n",
    "         ROOT + 'DTL1000-metadata-20211216/1970s.csv_110_musinstr.json',\n",
    "         ROOT + 'DTL1000-metadata-20211216/1980s.csv_110_musinstr.json', \n",
    "         ROOT + 'DTL1000-metadata-20211216/1990s.csv_110_musinstr.json',\n",
    "         ROOT + 'DTL1000-metadata-20211216/2000s.csv_110_musinstr.json',\n",
    "         ROOT + 'DTL1000-metadata-20211216/2010s.csv_110_musinstr.json']\n",
    "csv1960_TKN = 'metadata_#19**s.csv_110_musinstr_json'\n",
    "\n",
    "originalfile_FILE = ROOT + 'id_dtl1000-20210625.csv'\n",
    "originalfile_TKN = 'filename_original_#id_dtl1000-csv'\n",
    "\n",
    "mpal_FILE = ROOT + 'MPAL_CD_List_20210829.csv'\n",
    "mpal_TKN = 'metadata_#MPAL_CD_List_csv'\n",
    "\n",
    "#JeCompleteIndex_FILE = '/Users/peeters/_work/_projet/_2020_DigThatLick/_data/_new_simon2/DTL1000-metadata-20210411/JECompleteIndex_cleaned.csv'\n",
    "JeCompleteIndex_FILE = ROOT + 'JECompleteIndex_20210719.csv'\n",
    "JeCompleteIndex_TKN = 'metadata_#JE_Complete_Index_csv'\n",
    "\n",
    "musicbrainz_FILE = ROOT + 'MBquery-20210625.csv'\n",
    "musicbrainz_TKN = 'metadata_#musicbrainz'\n",
    "\n",
    "lord_sql_musiciansID_FILE = ROOT + 'musicians.json'\n",
    "instrument_acronym_mapping_FILE = ROOT + 'UIUC-instruments-20211216.xlsx'\n",
    "\n",
    "output_FILE = './dtl_1000-2021-12-17a.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define set of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file, separator=';'):\n",
    "    \n",
    "    csv_l = []\n",
    "    with open(file) as csvfile:\n",
    "        myreader = csv.reader(csvfile, delimiter=separator, quotechar='\"')\n",
    "        for row in myreader:\n",
    "            csv_l.append(row)\n",
    "\n",
    "    #print('---------------------------------')\n",
    "    print('>>> reading: {} -> {} lines'.format(file, len(csv_l)))\n",
    "    #print('---------------------------------')\n",
    "    return csv_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict(csv_l):\n",
    "    dict_l = []\n",
    "    nb_row = len(csv_l)\n",
    "    nb_col = len(csv_l[0])\n",
    "    for row in range(1, nb_row):\n",
    "        if len(csv_l[row])>1:\n",
    "            dict_d = {}\n",
    "            assert len(csv_l[row])==nb_col, 'wrong number of column for entry {}: requiring {} but get {}'.format(row, nb_col, len(csv_l[row]))\n",
    "            for col in range(0, nb_col):\n",
    "                dict_d[csv_l[0][col]] = csv_l[row][col]\n",
    "            dict_l.append(dict_d)\n",
    "    #print('---------------------------------')\n",
    "    print('>>> converted to {} entries with keys {}'.format(len(dict_l), dict_l[0].keys()))\n",
    "    #print('---------------------------------')\n",
    "    return dict_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(start_sec):\n",
    "    start_ms = int(np.floor(100000*(start_sec - np.floor(start_sec))))\n",
    "    start_m, start_s = divmod(np.floor(start_sec), 60)\n",
    "    start_h, start_m = divmod(start_m, 60)\n",
    "    output = '%01d.%02d.%02d.%06d' % (start_h, start_m, start_s, start_ms)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_time(string):\n",
    "    h, m, s_ms = string.split(':')\n",
    "    s, ms = s_ms.split('.')\n",
    "    time = 60*float(m) + float(s) + float(ms)/100000    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_key(data_d, key_l):\n",
    "    for key in key_l:\n",
    "        if key in data_d.keys():\n",
    "            data_d.pop(key)\n",
    "    return data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_key(input_d, output_d, key_l):\n",
    "    for key in key_l:\n",
    "        if key in input_d.keys():\n",
    "            if key in output_d.keys():\n",
    "                if isinstance(input_d[key], float):\n",
    "                    assert output_d[key]-input_d[key]<0.1, 'output_d[{}] have already a value \"{}\" which is different from \"{}\"'.format(key, input_d[key], output_d[key])\n",
    "                else:\n",
    "                    assert output_d[key] == input_d[key], 'output_d[{}] have already a value \"{}\" which is different from \"{}\"'.format(key, input_d[key], output_d[key])\n",
    "            output_d[key] = input_d[key]\n",
    "    return output_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(data_dl, key):\n",
    "    return sorted(set([data[key] for data in data_dl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- from https://stackoverflow.com/questions/32815640/how-to-get-the-difference-between-two-dictionaries-in-python\n",
    "def flatten_it(d):\n",
    "    if isinstance(d, list) or isinstance(d, tuple):\n",
    "        return tuple([flatten_it(item) for item in d])\n",
    "    elif isinstance(d, dict):\n",
    "        return tuple([(flatten_it(k), flatten_it(v)) for k, v in sorted(d.items())])\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data1_dl, key1, data2_dl, key2, key1add, do_replace=False):\n",
    "    \n",
    "    for data1_d in data1_dl: \n",
    "        data1_d['ok'] = 0\n",
    "    for data2_d in data2_dl: \n",
    "        data2_d['ok'] = 0\n",
    "\n",
    "    for data1_d in data1_dl:\n",
    "        \n",
    "        for data2_d in data2_dl:\n",
    "            \n",
    "            if data1_d[key1] ==  data2_d[key2]:\n",
    "                \n",
    "                data1_d['ok'] = 1\n",
    "                data2_d['ok'] = 1\n",
    "                    \n",
    "                if do_replace:\n",
    "                    # --- before replacing check that the value is the same\n",
    "                    if key1add in data1_d.keys():\n",
    "                        diff = set(flatten_it(data1_d[key1add] )) - set(flatten_it(data2_d))\n",
    "                        if len(diff): print(diff)\n",
    "\n",
    "                    data1_d[key1add] = data2_d\n",
    "                else:\n",
    "                    if key1add not in data1_d.keys():\n",
    "                        data1_d[key1add] = []\n",
    "                    \n",
    "                    data1_d[key1add].append(data2_d)\n",
    "    \n",
    "    # --- display INFO\n",
    "    L1 = len(data1_dl)\n",
    "    L1unique = len(get_unique(data1_dl, key1))\n",
    "    L1mapped = len([data1_d for data1_d in data1_dl if data1_d['ok']==1])\n",
    "    L2 = len(data2_dl)\n",
    "    L2unique = len(get_unique(data2_dl, key2))\n",
    "    L2mapped = len([data2_d for data2_d in data2_dl if data2_d['ok']==1])\n",
    "    print('---------------------------------')\n",
    "    print('do_replace: {}'.format(do_replace))\n",
    "    print('mapping data1[{}] to data2[{}] -> storing in data1[{}]'.format(key1, key2, key1add))\n",
    "    print('data1 len-mapped:{}/ len(unique()):{}/ len:{}'.format(L1mapped, L1unique, L1))\n",
    "    print('data2 len-mapped:{}/ len(unique()):{}/ len:{}'.format(L2mapped, L2unique, L2))\n",
    "    print('---------------------------------')\n",
    "\n",
    "\n",
    "    # --- remove 'ok' fields\n",
    "    for data1_d in data1_dl:\n",
    "        # --- data1_dl[:]['ok']=1\n",
    "        data1_d.pop('ok')\n",
    "\n",
    "        if key1add in data1_d.keys():\n",
    "            if isinstance(data1_d[key1add], list):\n",
    "                # --- data1_dl[:][key1add][:]['ok']=1   do_replace=False -> list\n",
    "                for data_d in data1_d[key1add]:\n",
    "                    if isinstance(data_d, dict):\n",
    "                        if 'ok' in data_d.keys():\n",
    "                            data_d.pop('ok')\n",
    "            else:\n",
    "                # --- data1_dl[:][key1add]['ok']=1   do_replace=True\n",
    "                if 'ok' in data1_d[key1add].keys():\n",
    "                    data1_d[key1add].pop('ok')\n",
    "                    \n",
    "        \n",
    "    return data1_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_map(data_dl, key):\n",
    "    map_d = {}\n",
    "    for data_d in data_dl:\n",
    "        map_d[data_d[key]] = data_d\n",
    "    return map_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create intrument_acronym mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/07/16 based on .xls\n",
    "assert os.path.exists(instrument_acronym_mapping_FILE), print(instrument_acronym_mapping_FILE)\n",
    "\n",
    "df = pd.read_excel(instrument_acronym_mapping_FILE)\n",
    "value1 = df['Unnamed: 1'].values[1:]\n",
    "value2 = df['Unnamed: 2'].values[1:]\n",
    "instrument_acronym_map = {}\n",
    "for num in range(len(value1)):\n",
    "    instrument_acronym_map[ value2[num]] =  value2[num]\n",
    "    instrument_acronym_map[value1[num].strip(' ')] = value2[num]\n",
    "instrument_acronym_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # --- 2021/07/19: based on Polina csv\n",
    "    instrument_acronym_map = {}\n",
    "    with open(ROOT + 'orig2DTL_instruments.csv') as csvfile:\n",
    "            myreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "            for row in myreader:\n",
    "                for num_col in range(1, len(row)):\n",
    "                    if len(row[num_col]):\n",
    "                        instrument_acronym_map[row[num_col]]  = row[1]\n",
    "    instrument_acronym_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse_performer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_performer_names(performer_names_str, musician_map=[], instrument_map=[]):\n",
    "    #print('----', performer_names_str)\n",
    "    musiciansANDinstruments_str_l = performer_names_str.split(')')\n",
    "    musiciansANDinstruments_str_l = musiciansANDinstruments_str_l[:-1]\n",
    "        \n",
    "    #print(performer_names_str)\n",
    "    #print('->', musiciansANDinstruments_str_l)\n",
    "    \n",
    "    musician_instrument_dl = []\n",
    "    \n",
    "    not_correct_l = []\n",
    "    for musiciansANDinstruments_str in musiciansANDinstruments_str_l:\n",
    "        musiciansANDinstruments_str = musiciansANDinstruments_str.lstrip(',')\n",
    "        \n",
    "        musicians_str, instruments_str = musiciansANDinstruments_str.split('(')\n",
    "        musician_str_l = musicians_str.split(',')\n",
    "        instrument_str_l = instruments_str.split(', ')\n",
    "        \n",
    "        #print(musicians_str)\n",
    "        #print('->', musician_str_l)\n",
    "        #print(instruments_str)\n",
    "        #print('->', instrument_str_l)\n",
    "\n",
    "        for musician_str in musician_str_l:\n",
    "            musician_str = musician_str.lstrip(' ')\n",
    "            musician_str = musician_str.rstrip(' ')\n",
    "\n",
    "            for instrument_str in instrument_str_l:\n",
    "                \n",
    "                # --- NEW 2021/07/16/ instrument acronym mapping\n",
    "                if instrument_str not in instrument_acronym_map.keys():\n",
    "                    print('key \"{}\"\" not in instrument map'.format(instrument_str))\n",
    "                    not_correct_l.append(instrument_str)\n",
    "                else:\n",
    "                    instrument_str = instrument_acronym_map[instrument_str]\n",
    "                \n",
    "                if (type(musician_map) is dict) and (type(instrument_map) is dict):\n",
    "                    if musician_str in musician_map.keys(): \n",
    "                        musician_id = musician_map[musician_str]\n",
    "                    else: \n",
    "                        musician_id = 0\n",
    "                    if instrument_str in instrument_map.keys(): \n",
    "                        instrument_id = instrument_map[instrument_str]\n",
    "                    else: \n",
    "                        instrument_id = 0\n",
    "                    musician_instrument_dl.append({'performer_name':musician_str, 'Lord_performer_ID':musician_id, 'instrument':instrument_str, 'Lord_instrument_ID':instrument_id})\n",
    "                else:\n",
    "                    musician_instrument_dl.append({'performer_name':musician_str, 'instrument':instrument_str})\n",
    "\n",
    "    return musician_instrument_dl, not_correct_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_performer_names(\"Anthony Braxton (cl, bcl, bs, ss, as), Muhal Richard Abrams (p)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_performer_names(\"Shelton Hemphill, Wardell Jones, Ed Anderson (t), Harry White, Henry Hicks (tb), Castor McCord (cl, ts), Ted McCord (as, cl), Crawford Wethington (as, bar, cl), Edgar Hayes (p), Benny James (bj), Hayes Alvis (sb), Willie Lynch (d), George Morton (v), Nat Leslie (a).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read style file\n",
    "\n",
    "**Load**\n",
    "\n",
    "- 1060 unique files\n",
    "    - 400 from JE (Jazz Encyclopedia)\n",
    "    - 660 AQA (from Illinois) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dl = convert_dict(read_csv(style_FILE, separator=','))\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    print('number of entry: ', len(style_dl))\n",
    "    print('number of unique key: ', len(get_unique(style_dl, 'file')))\n",
    "    pp.pprint( style_dl[0:5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean and move fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for style_d in style_dl:\n",
    "    style_d[style_TKN] = {'style': style_d['style']}\n",
    "    remove_key(style_d, ['style'])\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint( style_dl[0:5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get audio file duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/06/29: new to get the exact audio duration directy from the files\n",
    "do_parse_all_audio_files = False\n",
    "\n",
    "if do_parse_all_audio_files:\n",
    "    \n",
    "    def get_audio_duration():\n",
    "        dict_l = []\n",
    "        fullpathaudio_l = glob.glob(audio_DIR1) + glob.glob(audio_DIR2)\n",
    "        for idx, fullpathaudio in enumerate(tqdm(fullpathaudio_l)):\n",
    "            y, sr = librosa.load(fullpathaudio, sr=None)\n",
    "            duration = len(y)/sr\n",
    "            dict_d = {'file':fullpathaudio, 'duration':duration}\n",
    "            dict_l.append(dict_d)\n",
    "        return dict_l\n",
    "\n",
    "    audio_duration_dl = get_audio_duration()\n",
    "\n",
    "    with open(audioduration_FILE, 'w') as fid:\n",
    "        json.dump(audio_duration_dl, fid, indent=4)\n",
    "\n",
    "else:\n",
    "    with open(audioduration_FILE) as fid:\n",
    "        audio_duration_dl = json.load(fid)\n",
    "\n",
    "# --- CREATE A MAP\n",
    "map_duration_d = {}\n",
    "for audio_duration_d in audio_duration_dl:\n",
    "    audio_ID = audio_duration_d['file'].split('/')[-1].split('.')[0]\n",
    "    map_duration_d[audio_ID] = audio_duration_d['duration']\n",
    "    if audio_duration_d['duration']<100: print(audio_duration_d['duration'])\n",
    "\n",
    "# --- DO THE MAPPING\n",
    "for style_d in style_dl:\n",
    "    if not 'metadata' in style_d.keys(): style_d['metadata'] = {}\n",
    "    style_d['metadata']['track_duration'] = map_duration_d[ style_d['file'] ]\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(style_dl[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_localaudio:\n",
    "    # --- Disk seagate metal\n",
    "    fullpathaudio_l = glob.glob(audio_DIR1) + glob.glob(audio_DIR2)\n",
    "    \n",
    "    # --- Get root\n",
    "    rootaudio_map = {}\n",
    "    for fullpathaudio in fullpathaudio_l:\n",
    "        rootaudio_map[ fullpathaudio.split('/')[-1].split('.')[0] ] = fullpathaudio\n",
    "        \n",
    "    # --- Map\n",
    "    for style_d in style_dl:\n",
    "        style_d[audio_TKN] = rootaudio_map[style_d['file']]\n",
    "    \n",
    "    # +++++++++++++++++++++++++++++++++++++++\n",
    "    if do_verbose:\n",
    "        print('number of audio files: ', len(fullpathaudio_l) )\n",
    "        pp.pprint( style_dl[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentation file\n",
    "\n",
    "File\n",
    "- DTL_1000_segmentations.csv\n",
    "\n",
    "Each entry is a segment (annotated in melody or not).\n",
    "\n",
    "- 7084 segments (all the segments, only some of them have a melody annotation)\n",
    "- coming from 1060 unique files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_dl = convert_dict( read_csv(segment_FILE, separator=';') )\n",
    "\n",
    "# --- convert to float or int\n",
    "for segment_d in segment_dl:\n",
    "    segment_d['file'] = segment_d['file'].replace('.csv', '')\n",
    "    segment_d['onset'] = float(segment_d['onset'])\n",
    "    segment_d['duration'] = float(segment_d['duration'])\n",
    "    segment_d['total_duration'] = float(segment_d['total_duration'])\n",
    "    segment_d['number_segments'] = int(segment_d['number_segments'])\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    print('number of entry: ', len(segment_dl))\n",
    "    print('number of unique key: ', len(get_unique(segment_dl, 'file')))\n",
    "    pp.pprint(segment_dl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping filename JE*** -> AQA***\n",
    "\n",
    "**Problem:** seg_dl['file'] is refering both to \n",
    "- `AQAYpouYjFF0ZFWPdtmR8AI84pmCw8dD` and \n",
    "- `JE-2-047-06` files \n",
    "\n",
    "$\\rightarrow$ we need to map the 'JE-2-047-06' to their equivalent 'AQA***'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_dl[6223]['file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We do this using the following filename-to-filename map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read map filename\n",
    "mapfilename_dl = convert_dict( read_csv(mapfilename_FILE, separator=',') )\n",
    "\n",
    "# --- create a map\n",
    "mapfilename_map = {}\n",
    "for mapfilename_d in mapfilename_dl:\n",
    "    mapfilename_map[ mapfilename_d['file']] = mapfilename_d['dtl_id_short']\n",
    "\n",
    "# --- convert\n",
    "for segment_d in segment_dl:\n",
    "    if segment_d['file'] in mapfilename_map.keys():\n",
    "        print('converted file:', segment_d['file'] )   \n",
    "        segment_d['file'] = mapfilename_map[segment_d['file']]\n",
    "    else:\n",
    "        print('X unable to map file \"%s\":' % (segment_d['file']) )   \n",
    "        \n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(mapfilename_dl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping segment_dl -> style_dl\n",
    "\n",
    "We attach segment_dl (the segments) to the style_dl (the top structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dl = map_data(style_dl, 'file', segment_dl, 'file', segment_segment_TKN, do_replace=False)\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint( style_dl[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean and move fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, style_d in enumerate(style_dl):\n",
    "    assert segment_segment_TKN in style_d.keys(), print(idx, style_d)\n",
    "    for segment_d in style_d[segment_segment_TKN]:\n",
    "        style_d[segment_metadata_TKN] = {}\n",
    "        copy_key(segment_d, style_d[segment_metadata_TKN], ['file_id', 'total_duration', 'number_segments'])\n",
    "        #remove_key(segment_d, ['file', 'file_id', 'total_duration', 'number_segments'])\n",
    "        remove_key(segment_d, ['file_id', 'total_duration', 'number_segments'])\n",
    "        \n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(style_dl[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metadataANDsolo file\n",
    "\n",
    "This file contains the meta-data (artist title, album title, and the link to the melody annotation file).\n",
    "\n",
    "- 1685 segments with meta-data\n",
    "- HOWEVER there is 1732 .csv file of melody annotation -> (1732-1685) of them do not have meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataANDsolo_dl = convert_dict( read_csv(metadataANDsolo_FILE, separator=';') )\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    print('number of entry: ', len(metadataANDsolo_dl))\n",
    "    pp.pprint(metadataANDsolo_dl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add pitch-csv content to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "if do_pitchcsv:\n",
    "    for metadataANDsolo_d in metadataANDsolo_dl:\n",
    "        filename = pitch_DIR + metadataANDsolo_d['solo_id']  + '.csv'\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            pitch_dl = convert_dict( read_csv(filename, separator=',') )\n",
    "\n",
    "            for pitch_d in pitch_dl:\n",
    "                pitch_d['not_onset'] = float(pitch_d['onset'])\n",
    "                pitch_d['not_duration'] = float(pitch_d['duration'])\n",
    "                pitch_d['not_pitch'] = int(pitch_d['pitch'])\n",
    "                pitch_d['is_phrase_start'] = int(pitch_d['phrasbeg'])\n",
    "                pitch_d = remove_key(pitch_d, ['dtl_id_short', 'base_file', 'start', 'end', 'onset', 'duration', 'pitch', 'phrasbeg'])\n",
    "\n",
    "            metadataANDsolo_d[pitch_TKN] = pitch_dl\n",
    "        \n",
    "        else:\n",
    "            print('!!!', filename, 'does not exist')\n",
    "            \n",
    "    # +++++++++++++++++++++++++++++++++++++++\n",
    "    if do_verbose:\n",
    "        True #pp.pprint(metadataANDsolo_dl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping metadataANDsolo_dl -> style_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- the mapping is based on a short version of 'solo_id' \n",
    "#    -> temparory store it as 'solo_id_short'\n",
    "for metadataANDsolo_d in metadataANDsolo_dl: \n",
    "    metadataANDsolo_d['solo_id_short'] = metadataANDsolo_d['solo_id'][:32]\n",
    "#    -> map\n",
    "style_dl = map_data(style_dl, 'file', metadataANDsolo_dl, 'solo_id_short', metadataANDsolo_solo_TKN, do_replace=False)\n",
    "#    -> then remove\n",
    "for metadataANDsolo_d in metadataANDsolo_dl: \n",
    "    metadataANDsolo_d.pop('solo_id_short')\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(style_dl[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean and move fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for style_d in style_dl:\n",
    "    \n",
    "    \n",
    "    if metadataANDsolo_solo_TKN in style_d.keys():\n",
    "        style_d[metadataANDsolo_metadata_TKN] = {}\n",
    "        for metadataANDsolo_d in style_d[metadataANDsolo_solo_TKN]:\n",
    "            to_move_l = ['area','band_name','disk_title','session_date','leader_name','medium_record_number','medium_title','performer_names','session_date','track_title']\n",
    "            copy_key(metadataANDsolo_d, style_d[metadataANDsolo_metadata_TKN], to_move_l)\n",
    "            remove_key(metadataANDsolo_d, to_move_l)\n",
    "\n",
    "            onset = convert_string_to_time(metadataANDsolo_d['solo_start'])\n",
    "            offset = convert_string_to_time(metadataANDsolo_d['solo_end'])\n",
    "            metadataANDsolo_d['onset'] = onset\n",
    "            metadataANDsolo_d['duration'] = offset - onset\n",
    "            remove_key(metadataANDsolo_d, ['solo_start', 'solo_end'])\n",
    "\n",
    "        \n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(style_dl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020/01/26 Add files from Simon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files coming from Illinois (AQA***) comes with an extra set of meta-data stored as a set of json files.\n",
    "This is threfore for 660/1060 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1960_dl = []\n",
    "for csv1960_FILE in csv1960_FILE_l:\n",
    "    with open(csv1960_FILE) as fid: \n",
    "        tmp_dl = json.load(fid)\n",
    "    for key in tmp_dl[0].keys(): \n",
    "        csv1960_dl.append( tmp_dl[0][key] )\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    print('total nb files: ', len(csv1960_dl) )\n",
    "    print('number of entry: ', len(csv1960_dl))\n",
    "    print('number of unique key: ', len(get_unique(csv1960_dl, 'audioid')))\n",
    "    pp.pprint(csv1960_dl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_key_value(input, key, value):\n",
    "    if key in input.keys():\n",
    "        if not input[key]==value:\n",
    "            print('> key \"{}\" is already assigned to \"{}\", cannot assign it to \"{}\"'.format(key, input[key], value))\n",
    "    else:\n",
    "        input[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_musician_instrument_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/06/29\n",
    "# --- we need to get the dictionary\n",
    "\n",
    "# --- 2021/07/15\n",
    "# /Users/peeters/_work/_projet/_2020_DigThatLick/_dtl_sqlite/musicians.json\n",
    "\n",
    "def create_musician_instrument_map(csv1960_dl):\n",
    "    musician_map = {}\n",
    "    instrument_map = {}\n",
    "    for csv1960_d in csv1960_dl:\n",
    "        entry_l = csv1960_d['musician_instrument']\n",
    "        for entry in entry_l:\n",
    "            assign_key_value(musician_map, entry['musician_name'], entry['musician_id'])\n",
    "            assign_key_value(instrument_map, entry['instrument_name'], entry['instrument_id'])\n",
    "    return musician_map, instrument_map\n",
    "musician_map, instrument_map = create_musician_instrument_map(csv1960_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lord_sql_musiciansID_FILE) as fid:\n",
    "    entry_dl = json.load(fid)\n",
    "\n",
    "musician_map = {}\n",
    "for entry_d in entry_dl:\n",
    "    if entry_d['name'] in musician_map.keys():\n",
    "        # --- if already exist -> convert to list\n",
    "        if type(musician_map[entry_d['name']]) is int:\n",
    "            tmp = musician_map[entry_d['name']]\n",
    "            musician_map[entry_d['name']] = []\n",
    "            musician_map[entry_d['name']].append(tmp)\n",
    "        musician_map[entry_d['name']].append( entry_d['id'] )\n",
    "    else:\n",
    "        musician_map[entry_d['name']] = entry_d['id']\n",
    "    \n",
    "\n",
    "#key_l = [key for key in musician_map.keys()]\n",
    "#for key in key_l:\n",
    "#    pp.pprint( musician_map[ key ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dl = map_data(style_dl, 'file', csv1960_dl, 'audioid', csv1960_TKN, do_replace=True)\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(style_dl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *** NEW parse 'perfomer_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/06/29\n",
    "# --- we need to split performer_names\n",
    "count=0\n",
    "for idx, style_d in enumerate(style_dl):\n",
    "    if metadataANDsolo_metadata_TKN in style_d.keys():\n",
    "        try:\n",
    "            style_d[metadataANDsolo_metadata_TKN]['performers_instruments'] = parse_performer_names(style_d[metadataANDsolo_metadata_TKN]['performer_names'], musician_map, instrument_map)\n",
    "        except:\n",
    "            print(idx, style_d[metadataANDsolo_metadata_TKN]['performer_names'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- to check the format\n",
    "for idx, style_l in enumerate(style_dl):\n",
    "    if metadataANDsolo_metadata_TKN in style_l.keys():\n",
    "        print(idx, '---------------------------------------------')\n",
    "        pp.pprint(style_l[metadataANDsolo_metadata_TKN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW get origin and track_number_on_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/06/29\n",
    "origin_l = []\n",
    "track_number_on_disk_l = []\n",
    "for style_d in style_dl:\n",
    "    if csv1960_TKN in style_d.keys():\n",
    "        origin = style_d[csv1960_TKN]['filename'].split('/')[1]\n",
    "        style_d['metadata']['origin'] = origin\n",
    "        track_number_on_disk = style_d[csv1960_TKN]['filename'].split('/')[-1].split(' ')[0]\n",
    "        style_d['metadata']['CD_track_number'] = track_number_on_disk\n",
    "    else:\n",
    "        style_d['metadata']['origin'] = 'jazz-encyclopedia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW keep fingerprint field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dl = convert_dict( read_csv(originalfile_FILE, separator=',') )\n",
    "\n",
    "if not do_fingerprint:\n",
    "    for new_d in new_dl:\n",
    "        new_d = remove_key(new_d, ['fingerprint'])\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(new_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dl = map_data(style_dl, 'file', new_dl, 'audio_id', originalfile_TKN, do_replace=True)\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    pp.pprint(style_dl[1][originalfile_TKN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW get decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/06/29: get decade\n",
    "decade_l = []\n",
    "for style_d in style_dl:\n",
    "    decade = style_d[originalfile_TKN]['filename'].split('/')[-2]\n",
    "    if not 'metadata' in style_d.keys(): style_d['metadata'] = {}\n",
    "    style_d['metadata']['decade'] = decade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPAL: raw disk-info\n",
    "\n",
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpal_dl = convert_dict( read_csv(mpal_FILE, separator=',') )\n",
    "\n",
    "for mpal_d in mpal_dl: \n",
    "    mpal_d.pop('')\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    print('number of entry: ', len(mpal_dl))\n",
    "    print('number of unique key: ', len(get_unique(mpal_dl, 'Catalog #')))\n",
    "    pp.pprint(mpal_dl[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpal_map = convert_to_map(mpal_dl, 'Catalog #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "for style_d in style_dl: \n",
    "    if csv1960_TKN in style_d.keys():\n",
    "        if len(style_d[csv1960_TKN]):\n",
    "            lookfor_key = style_d[csv1960_TKN]['labelid']\n",
    "            if lookfor_key in mpal_map.keys():\n",
    "                style_d[mpal_TKN] = mpal_map[lookfor_key]\n",
    "                count3 = count3+1\n",
    "            else:\n",
    "                count1 = count1+1\n",
    "    else:\n",
    "        count2 = count2 + 1\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "if do_verbose:\n",
    "    print('number of files w/o metadata19_targetkeyname: ', count2)\n",
    "    print('number of files with metadata19_targetkeyname but no mpal: ', count1)\n",
    "    print('number of matches', count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(style_dl[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-data for JE (< 1960)\n",
    "\n",
    "2021/05/18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = read_csv(JeCompleteIndex_FILE, separator=',')\n",
    "header_l = data_l[0]\n",
    "\n",
    "map_d = {'Aufnahmeort':'area', \n",
    "         'Artist':'band_name', \n",
    "         'Aufnahmedatum':'session_date', \n",
    "         'Title':'track_title', \n",
    "         'Besetzung':'performer_names',\n",
    "         'CD': 'medium_record_number',\n",
    "         'Track': 'track_title',\n",
    "         'Boxnumber': '-Boxnumber',\n",
    "         'Composer': '-Composer',\n",
    "         '': '-'\n",
    "        }\n",
    "JE_d = {}\n",
    "count_collection = 0\n",
    "count_cd = 0\n",
    "count_track = 0\n",
    "\n",
    "for l in range(1, len(data_l)):\n",
    "    if len(data_l[l][0])==0 and len(data_l[l][1])==0:\n",
    "        # --- Blank line\n",
    "        True\n",
    "    elif len(data_l[l][0])>0 and len(data_l[l][3])==0:\n",
    "        # --- Collection line\n",
    "        collection_name = data_l[l][0]\n",
    "        count_collection += 1\n",
    "        count_cd = 0\n",
    "        count_track = 0\n",
    "        #print('Collection', data_l[l])\n",
    "    elif len(data_l[l][0])>0 and len(data_l[l][1])==0 and len(data_l[l][3])>0:\n",
    "        # --- CD line\n",
    "        #print('CD', data_l[l])\n",
    "        cd_id = data_l[l][0]\n",
    "        cd_name = data_l[l][3]\n",
    "        count_cd += 1\n",
    "        count_track = 0\n",
    "    else:\n",
    "        # --- Track\n",
    "        #print('Track', data_l[l])x\n",
    "        entry_d = {}\n",
    "        for ll in range(len(header_l)):\n",
    "            #entry_d[header_l[ll]] = data_l[l][ll]   # --- Original\n",
    "            entry_d[map_d[header_l[ll]]] = data_l[l][ll] # --- Translated to English\n",
    "        \n",
    "        entry_d['medium_title'] = cd_name\n",
    "        entry_d['disk_title'] = 'The Encyclopedia of Jazz, ' + collection_name\n",
    "        \n",
    "        tmp = entry_d['session_date'].split('/')\n",
    "        if len(tmp)>2:\n",
    "            entry_d['session_date'] = tmp[2] + '-' + tmp[1] + '-' + tmp[0]\n",
    "        #entry_d['performer_names'] = ', '.join(sorted(entry_d['performer_names'].strip('.').split(', ')))\n",
    "        \n",
    "        \n",
    "        entry_d.pop('-Boxnumber')\n",
    "        entry_d.pop('-Composer')\n",
    "        entry_d.pop('-')\n",
    "        \n",
    "        count_track += 1\n",
    "        entry_d['CD_track_number'] = count_track\n",
    "        entry_d['CD_disk_number'] = count_cd\n",
    "        entry_d['collection_number'] = count_collection\n",
    "\n",
    "        str_cd = '{0:3d}'.format(count_cd).replace(' ', '0')\n",
    "        str_track = '{0:2d}'.format(count_track).replace(' ', '0')\n",
    "        key = 'JE-{}-{}-{}.wav'.format(count_collection, str_cd, str_track)\n",
    "        JE_d[key] = entry_d\n",
    "\n",
    "        if count_track==0: print(key, '|', collection_name, '|', cd_id, cd_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_l = [key for key in JE_d.keys()]\n",
    "idx = 100\n",
    "print(key_l[idx], JE_d[key_l[idx]])\n",
    "print(key_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, style_d in enumerate(style_dl):\n",
    "    tmp = style_d[originalfile_TKN]['filename'].split('/')[-1]\n",
    "    if 'JE-' in tmp:\n",
    "        style_d[JeCompleteIndex_TKN] = JE_d[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(style_dl[1058][JeCompleteIndex_TKN])\n",
    "pp.pprint(style_dl[1058][metadataANDsolo_metadata_TKN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *** NEW parse 'perfomer_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021/06/29\n",
    "# --- we need to split performer_names\n",
    "not_correct_l = []\n",
    "count=0\n",
    "for idx, style_d in enumerate(style_dl):\n",
    "    if JeCompleteIndex_TKN in style_d.keys():\n",
    "        try:\n",
    "            style_d[JeCompleteIndex_TKN]['performers_instruments'], tmp = parse_performer_names(style_d[JeCompleteIndex_TKN]['performer_names'], musician_map, instrument_map)\n",
    "            not_correct_l.append(tmp)\n",
    "        except:\n",
    "            print(idx, '----', style_d[JeCompleteIndex_TKN]['performer_names'])\n",
    "            \n",
    "# --- to check the format\n",
    "style_dl[19][JeCompleteIndex_TKN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "set(flatten(not_correct_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW Music-Brainz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dl = convert_dict( read_csv(musicbrainz_FILE, separator=',') )\n",
    "style_dl = map_data(style_dl, 'file', new_dl, 'audio_id', musicbrainz_TKN, do_replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for style_d in style_dl:\n",
    "    pp.pprint(style_d[musicbrainz_TKN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rename_fields(entry_l, old_field, new_field):\n",
    "    \n",
    "    if not type(entry_l) is list:\n",
    "        entry_l = [entry_l]\n",
    "        \n",
    "    for entry in entry_l:\n",
    "        if old_field in entry.keys():\n",
    "            if len(new_field):\n",
    "                if new_field in entry.keys(): # --- there is already something in new_field -> we add\n",
    "                    for old_field_key in entry[old_field].keys():\n",
    "                        entry[new_field][old_field_key] = entry[old_field][old_field_key]\n",
    "                else: # --- new_field does not exist -> we create it\n",
    "                    entry[new_field] = entry[old_field]\n",
    "\n",
    "            if not new_field == old_field:\n",
    "                entry.pop(old_field)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IL / solo      1\n",
    "# --- IL / w/o solo  0\n",
    "# --- JE / solo      19\n",
    "# --- JE / w/o solo  103\n",
    "for num in range(1200):\n",
    "    True #print(num, style_dl[num]['metadata']['origin'], 'solo_#metadata_full_compressed_v10_csv' in style_dl[num].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#style_dl = [style_dl[idx] for idx in [1, 0, 19, 103]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for style_d in style_dl:\n",
    "    my_rename_fields(style_d, 'file', 'audio-ID')\n",
    "\n",
    "    my_rename_fields(style_d, 'metadata_#styles_csv', '1_metadata')\n",
    "\n",
    "    my_rename_fields(style_d['metadata_#musicbrainz'], 'audio_id', '')\n",
    "    my_rename_fields(style_d, 'metadata_#musicbrainz', '2_metadata')\n",
    "\n",
    "    ###style_d['metadata']['fingerprint'] = style_d['filename_original_#id_dtl1000-csv']['fingerprint']\n",
    "    my_rename_fields(style_d, 'filename_original_#id_dtl1000-csv', '')\n",
    "\n",
    "\n",
    "    category = 'segment_#DTL_1000_segmentations3_csv'\n",
    "    if category in style_d.keys():\n",
    "        my_rename_fields(style_d, category, 'structure')\n",
    "        my_rename_fields(style_d['structure'], 'file', '')\n",
    "        my_rename_fields(style_d['structure'], 'onset', 'segment_start')\n",
    "        my_rename_fields(style_d['structure'], 'duration', 'segment_duration')\n",
    "        my_rename_fields(style_d['structure'], 'instrument', 'solo_instrument')\n",
    "        my_rename_fields(style_d['structure'], 'num_instruments', 'solo_instrument_count')\n",
    "        my_rename_fields(style_d['structure'], 'main_type', 'segment_category')\n",
    "        my_rename_fields(style_d['structure'], 'has_improvised', 'is_improvised')\n",
    "        my_rename_fields(style_d['structure'], 'usable', 'is_usable')\n",
    "        my_rename_fields(style_d['structure'], 'segment_pos', 'segment_number')\n",
    "        my_rename_fields(style_d['structure'], 'segment_id', 'segment_ID')\n",
    "\n",
    "    category = 'metadata_#DTL_1000_segmentations3_csv'\n",
    "    if category in style_d.keys():\n",
    "        my_rename_fields(style_d[category], 'number_segments', 'segment_count')\n",
    "        my_rename_fields(style_d[category], 'total_duration', '')\n",
    "        my_rename_fields(style_d[category], 'file_id', 'dtl1000_file_number')\n",
    "        my_rename_fields(style_d, category, 'metadata_#from-structure')\n",
    "\n",
    "    # --- seulement pour solo\n",
    "    category = 'solo_#metadata_full_compressed_v10_csv'\n",
    "    if category in style_d.keys():\n",
    "        my_rename_fields(style_d, category, 'solo')\n",
    "        my_rename_fields(style_d['solo'], 'solo_id', 'solo_ID')\n",
    "        my_rename_fields(style_d['solo'], 'possible_solo_performer_names', '')\n",
    "        my_rename_fields(style_d['solo'], 'instrument_label', 'solo_instrument')\n",
    "        my_rename_fields(style_d['solo'], 'onset', 'solo_start')\n",
    "        my_rename_fields(style_d['solo'], 'duration', 'solo_duration')\n",
    "        my_rename_fields(style_d['solo'], 'solo_transcription', '') ###\n",
    "\n",
    "    # --- seulement pour solo\n",
    "    category = 'metadata_#metadata_full_compressed_v10_csv'\n",
    "    if category in style_d.keys():\n",
    "        my_rename_fields(style_d[category], 'area', 'session_location')\n",
    "        my_rename_fields(style_d[category], 'disk_title', 'album_title')\n",
    "        my_rename_fields(style_d[category], 'leader_name', 'band_leader')\n",
    "        my_rename_fields(style_d[category], 'medium_record_number', 'CD_disc_number')\n",
    "        my_rename_fields(style_d[category], 'medium_title', 'CD_disc_title')\n",
    "        my_rename_fields(style_d[category], 'performer_names', 'performers_instruments_unparsed')\n",
    "        my_rename_fields(style_d, category, 'metadata_#from-solo')\n",
    "\n",
    "    # --- seulement pour Illinois\n",
    "    category = 'metadata_#19**s.csv_110_musinstr_json'\n",
    "    if category in style_d.keys():\n",
    "        my_rename_fields(style_d[category], 'album', '')\n",
    "        my_rename_fields(style_d[category], 'labelid', '')\n",
    "        #my_rename_fields(style_d[category], 'trackname', '')\n",
    "        my_rename_fields(style_d[category], 'release_id', 'Lord_release_ID')\n",
    "        my_rename_fields(style_d[category], 'session_full_id', 'Lord_session_ID')\n",
    "        my_rename_fields(style_d[category], 'session_id', '')\n",
    "        my_rename_fields(style_d[category], 'tune_id', 'Lord_tune_ID')\n",
    "        my_rename_fields(style_d[category], 'filename', '')\n",
    "        #my_rename_fields(style_d[category], 'title', '')\n",
    "        my_rename_fields(style_d[category], 'segmentid', '')\n",
    "        my_rename_fields(style_d[category], 'audioid', '')\n",
    "        my_rename_fields(style_d[category], 'musician_instrument', 'performers_instruments')\n",
    "        my_rename_fields(style_d[category], 'time_location', 'session_location_date')\n",
    "        my_rename_fields(style_d[category], 'track_id', 'track_ID')\n",
    "        my_rename_fields(style_d, category, 'metadata_#from-1960csv')\n",
    "\n",
    "    # --- seulement pour Illinois\n",
    "    category = 'metadata_#MPAL_CD_List_csv'\n",
    "    if category in style_d.keys():\n",
    "        my_rename_fields(style_d[category], 'Catalog #', 'CD_ID')\n",
    "        my_rename_fields(style_d[category], 'Artist', 'CD_artist')\n",
    "        my_rename_fields(style_d[category], 'Album Title', 'CD_title')\n",
    "        my_rename_fields(style_d[category], '# Discs', 'CD_disc_count')\n",
    "        my_rename_fields(style_d[category], '2621', '')\n",
    "        my_rename_fields(style_d[category], '30377', '')\n",
    "        my_rename_fields(style_d, category, 'metadata_#from-MPAL')\n",
    "\n",
    "    # --- seulement pour Jazz-Encyclopedia\n",
    "    category = 'metadata_#JE_Complete_Index_csv'\n",
    "    if category in style_d.keys():\n",
    "        #my_rename_fields(style_d[category], 'track_title', '')\n",
    "        my_rename_fields(style_d[category], 'medium_record_number', '')\n",
    "        #my_rename_fields(style_d[category], 'band_name', '')\n",
    "        my_rename_fields(style_d[category], 'area', 'sesson_location')\n",
    "        #my_rename_fields(style_d[category], 'session_date', '')\n",
    "        my_rename_fields(style_d[category], 'performer_names', 'performers_instruments_unparsed')\n",
    "        my_rename_fields(style_d[category], 'medium_title', 'CD_disc_title')\n",
    "        my_rename_fields(style_d[category], 'disk_title', '')\n",
    "        my_rename_fields(style_d[category], 'collection_number', '')\n",
    "        my_rename_fields(style_d, category, 'metadata_#from-JE-complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(style_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >> Save the main file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort field by alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "for l in range(len(style_dl)):\n",
    "    style_dl[l] = OrderedDict(sorted(style_dl[l].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d-%Hh-%Mm-%Ss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_d = {}\n",
    "store_d['version'] = dt_string\n",
    "store_d['collection'] = style_dl\n",
    "with open(output_FILE, 'w') as fid:\n",
    "    json.dump(store_d, fid, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(style_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zadazdazdz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dl = [style_d for style_d in style_dl if '/JE-' in style_d['filename_original_#id_dtl1000-csv']['filename']]\n",
    "len(sub_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'filename_original_#id_dtl1000-csv' # 400/400 - 660/660\n",
    "\n",
    "key = 'metadata_#19**s.csv_110_musinstr_json'   # 0/400 - 660/660\n",
    "key = 'metadata_#MPAL_CD_List_csv' # 0/400 - 660/660\n",
    "\n",
    "key = 'segment_#DTL_1000_segmentations_csv' # 400/400 - 660/660\n",
    "\n",
    "key = 'metadata_#metadata_full_compressed_v9_csv'\n",
    "#key = 'segment_solo_#metadata_full_compressed_v7_csv'\n",
    "\n",
    "select_dl = [style_d for style_d in sub_dl if key in style_d.keys()]\n",
    "len(select_dl)\n",
    "#select_dl[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillin = '-----'\n",
    "def describe(data, fillin_tot = ''):\n",
    "    if type(data) is list:\n",
    "        print(\"{}{}\".format(fillin_tot, '[:]'))\n",
    "        if len(data):\n",
    "            describe(data[0], fillin_tot + fillin)\n",
    "    elif type(data) is dict:\n",
    "        for key in data.keys():\n",
    "            if type(data[key]) in (str, float, int):\n",
    "                print(\"{}'{}'\\t{}\".format(fillin_tot, key, data[key]))\n",
    "            else:\n",
    "                print(\"{}'{}'\".format(fillin_tot, key))\n",
    "            describe(data[key], fillin_tot + fillin)\n",
    "    else:\n",
    "        True\n",
    "        #print(fillin + 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, style_d in enumerate(style_dl):\n",
    "    if 'segment_solo_#metadata_full_compressed_v7_csv' in style_d.keys():\n",
    "        if len(style_d['segment_solo_#metadata_full_compressed_v7_csv'][0]['solo_performer_name']):\n",
    "            print('')\n",
    "            print(idx)\n",
    "            describe(style_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(style_dl[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(61)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.703px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
